# ğŸ¥œğŸ¤– NutriSort-Pi  
**Inteligentny system detekcji i sortowania nakrÄ™tek z uÅ¼yciem YOLOv8 i Raspberry Pi**

![Schemat systemu](conveyor.png)

NutriSort-Pi to w peÅ‚ni zintegrowany system sÅ‚uÅ¼Ä…cy do wykrywania i sortowania nakrÄ™tek (lub innych maÅ‚ych obiektÃ³w) w czasie rzeczywistym. Wykorzystuje kamerÄ™ USB, Raspberry Pi, model YOLOv8 oraz komponenty mechaniczne â€“ serwomechanizm i silnik krokowy â€“ aby skutecznie zidentyfikowaÄ‡ i przekierowaÄ‡ wybrane elementy. Projekt moÅ¼e znaleÅºÄ‡ zastosowanie w edukacji, automatyzacji produkcji i systemach inspekcji wizyjnej.

---

## ğŸ“ Struktura projektu

```
custom_data/              # Surowe dane treningowe (obrazy + etykiety YOLO)
data/                     # Dane przetworzone (train/val)
runs/                     # Wyniki treningu YOLO
data.yaml                 # Konfiguracja klas i Å›cieÅ¼ek danych
make_photos.py            # Skrypt do robienia zdjÄ™Ä‡ kamerÄ…
project_raspberry.py      # GÅ‚Ã³wny skrypt detekcji i sterowania GPIO
schema.png                # Schemat poÅ‚Ä…czeÅ„ elektrycznych
train_val_split.py        # Skrypt podziaÅ‚u danych
Training_yolo.ipynb       # Notebook do trenowania modelu
yolov8n.pt                # Model YOLO (bazowy lub wytrenowany)
conveyor.png              # ZdjÄ™cie stanowiska fizycznego (taÅ›ma)
```

---

## âš™ï¸ Etapy realizacji

1. **Konfiguracja Raspberry Pi**  
   Instalacja systemu, Å›rodowiska Python i bibliotek (`ultralytics`, `opencv-python`, `RPi.GPIO`).

2. **Tworzenie danych**  
   UÅ¼ycie `make_photos.py` do robienia zdjÄ™Ä‡ obiektÃ³w z kamerki.

3. **Labelowanie danych**  
   Oznaczenie obiektÃ³w w Label Studio i eksport w formacie YOLOv8.

4. **Trenowanie modelu YOLOv8**  
   W `Training_yolo.ipynb`, z uÅ¼yciem `data.yaml`. Rezultaty zapisujÄ… siÄ™ w `runs/`.

5. **Wykrywanie i sterowanie**  
   Skrypt `project_raspberry.py` analizuje obraz z kamery, a gdy nakrÄ™tka znajduje siÄ™ w centrum kadru â€“ uruchamia serwo.

6. **Integracja z mechanikÄ…**  
   PodÅ‚Ä…czenie serwomechanizmu i silnika krokowego do Raspberry Pi oraz testowanie na fizycznej taÅ›mie.

---

## ğŸ”© Wykorzystane komponenty

- ğŸ§  Raspberry Pi 3B+ lub 4
- ğŸ¥ Kamera USB
- ğŸ¦¾ Serwomechanizm (np. SG90)
- ğŸ”„ Silnik krokowy 12V
- âš™ï¸ Sterownik silnika krokowego AVT1725
- ğŸ”Œ Zasilacz, pÅ‚ytka stykowa, przewody

---

## ğŸš€ Uruchomienie

1. Instalacja zaleÅ¼noÅ›ci:
   ```bash
   pip install ultralytics opencv-python RPi.GPIO
   ```

2. Uruchomienie programu:
   ```bash
   python project_raspberry.py
   ```

3. Obiekt `"nut"` wykryty w **czerwonym okrÄ™gu** (Å›rodku obrazu) aktywuje serwo.

---

## ğŸ§  Model YOLOv8

- UÅ¼ywany model: `YOLOv8n` (lekki i szybki)
- Trening z wykorzystaniem wÅ‚asnych danych
- Etykiety eksportowane z Label Studio
- Konfiguracja danych: `data.yaml`

---

## ğŸ–¼ï¸ Wizualizacje

| ğŸ“· Stanowisko fizyczne | âš™ï¸ Schemat elektroniki |
|------------------------|------------------------|
| ![conveyor](conveyor.png) | ![schema](schema.png) |

---

## ğŸ“½ï¸ Link do wideo demonstracyjnego

ğŸ¬ [Kliknij tutaj, aby obejrzeÄ‡ demonstracjÄ™](https://youtu.be/Ah3cAaL4SCw) 

---

## ğŸ“Œ Dodatkowe informacje

- Centrum obrazu oznaczone jest czerwonym okrÄ™giem jako strefa aktywacji
- Åatwa rozbudowa o nowe klasy obiektÃ³w (`bolt`, `washer`, itp.)
- MoÅ¼liwoÅ›Ä‡ edycji kÄ…ta obrotu serwa i parametrÃ³w detekcji

---

## ğŸ“ƒ Autorzy

Szymon Skrzypek
Karol Piotrowski 
Dawid Socha
Patryk Sieja
---

# ğŸ‡¬ğŸ‡§ NutriSort-Pi  
**Intelligent Nut Detection and Sorting System using YOLOv8 and Raspberry Pi**

![System schema](conveyor.png)

NutriSort-Pi is a fully integrated real-time object detection and sorting system designed for small items like nuts. It uses a USB camera, Raspberry Pi, YOLOv8 neural network, and mechanical components (servo and stepper motor) to identify and physically sort items on a conveyor. Ideal for educational, prototyping, or automation purposes.

---

## ğŸ“ Project Structure

```
custom_data/              # Raw training data (images + YOLO labels)
data/                     # Train/validation split
runs/                     # YOLOv8 training results
data.yaml                 # Model configuration file
make_photos.py            # Image capture script
project_raspberry.py      # Main detection + GPIO control script
schema.png                # Circuit and wiring diagram
train_val_split.py        # Dataset splitting script
Training_yolo.ipynb       # Training notebook for YOLOv8
yolov8n.pt                # Pretrained or trained YOLOv8 model
conveyor.png              # Conveyor setup photo
```

---

## âš™ï¸ Project Workflow

1. **Raspberry Pi setup**  
   Install Python, pip, and required libraries (`ultralytics`, `opencv-python`, `RPi.GPIO`).

2. **Image dataset creation**  
   Use `make_photos.py` to capture photos from a USB webcam.

3. **Data labeling**  
   Use Label Studio to label `"nut"` objects and export to YOLO format.

4. **Model training (YOLOv8)**  
   Train the model using `Training_yolo.ipynb` and `data.yaml`.

5. **Detection & control**  
   `project_raspberry.py` detects objects and activates a servo if a nut is in the center of the frame (red circle).

6. **Mechanical integration**  
   Connect servo and stepper to Raspberry Pi and test physical sorting.

---

## ğŸ”© Components Used

- ğŸ§  Raspberry Pi 3B+ or 4
- ğŸ¥ USB webcam
- ğŸ¦¾ Servo motor (e.g., SG90)
- ğŸ”„ 12V stepper motor
- âš™ï¸ Stepper motor driver (AVT1725)
- ğŸ”Œ Power supply, breadboard, jumper wires

---

## ğŸš€ How to Run

1. Install dependencies:
   ```bash
   pip install ultralytics opencv-python RPi.GPIO
   ```

2. Run the detection system:
   ```bash
   python project_raspberry.py
   ```

3. When a `"nut"` is detected in the center (red circle), the servo activates. ğŸ¥œâ¡ï¸ğŸ”

---

## ğŸ§  YOLOv8 Model

- Model: `YOLOv8n` (lightweight and efficient)
- Custom data trained using YOLOv8
- Labels generated in Label Studio
- Config via `data.yaml`

---

## ğŸ–¼ï¸ Visuals

| ğŸ“· Conveyor setup | âš™ï¸ Wiring diagram |
|------------------|------------------|
| ![conveyor](conveyor.png) | ![schema](schema.png) |

---

## ğŸ“½ï¸ Demo video link

ğŸ¬ [Click here to watch the demo](https://youtu.be/Ah3cAaL4SCw) 

---
## ğŸ“Œ Additional Notes

- Center of the frame marked with a red circle = activation zone
- Easily extendable to new classes (`bolt`, `washer`, etc.)
- Adjustable servo parameters and detection thresholds

---

## ğŸ“ƒ Authors

Szymon Skrzypek
Karol Piotrowski 
Dawid Socha
Patryk Sieja
